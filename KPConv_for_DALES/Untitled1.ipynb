{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de91771-1b78-409f-b60f-23af25d1a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858a5622-0b40-4f17-98e5-a35c73d7625c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e208e55-ddd5-4715-8912-d51cd4e0424b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "672ec604-2b9d-43d3-a86a-3ed89322e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f558db-d4af-4df6-9a5e-88d238629743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98f59db9-0144-41b6-88d0-f82bc58ef4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "Num GPUs Available:  1\n",
      "WARNING:tensorflow:AutoGraph could not transform <function normalize_img at 0x286e712d0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function normalize_img at 0x286e712d0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function normalize_img at 0x286e712d0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function normalize_img at 0x286e712d0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function normalize_img at 0x286e712d0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function normalize_img at 0x286e712d0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 14:52:20.049466: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467/469 [============================>.] - ETA: 0s - loss: 0.1634 - accuracy: 0.9516"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 14:52:26.321145: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 7s 12ms/step - loss: 0.1633 - accuracy: 0.9517 - val_loss: 0.0589 - val_accuracy: 0.9813\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0441 - accuracy: 0.9857 - val_loss: 0.0383 - val_accuracy: 0.9872\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0274 - accuracy: 0.9917 - val_loss: 0.0404 - val_accuracy: 0.9887\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0315 - val_accuracy: 0.9903\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0399 - val_accuracy: 0.9882\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.0363 - val_accuracy: 0.9890\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0441 - val_accuracy: 0.9890\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.0377 - val_accuracy: 0.9893\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0458 - val_accuracy: 0.9890\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.0371 - val_accuracy: 0.9902\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0382 - val_accuracy: 0.9912\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0411 - val_accuracy: 0.9901\n",
      "CPU times: user 35.1 s, sys: 25.4 s, total: 1min\n",
      "Wall time: 1min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dd1d7820>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad083551-f8fa-4ae1-b0bd-f7082b31f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "878e16aa-5129-4f91-9c52-a716d3ff32c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelVisualizer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mKPCNN_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelPointCNN\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mKPFCNN_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelPointFCNN\n",
      "File \u001b[0;32m~/Desktop/KPConv_for_DALES/utils/visualizer.py:35\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmayavi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mlab\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_editor\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mge\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# PLY reader\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m write_ply, read_ply\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib'"
     ]
    }
   ],
   "source": [
    "from utils.config import Config\n",
    "from utils.visualizer import ModelVisualizer\n",
    "from models.KPCNN_model import KernelPointCNN\n",
    "from models.KPFCNN_model import KernelPointFCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c76a2-82f6-4fe9-b2ca-c0f916d766bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f01368e-4c6d-4682-be24-e4b073fb17fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d39ff89d-4295-4a06-a90f-f69b43229428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1591.3380126953125\n",
      "199 1069.477294921875\n",
      "299 720.2466430664062\n",
      "399 486.37457275390625\n",
      "499 329.6437683105469\n",
      "599 224.5315399169922\n",
      "699 153.98304748535156\n",
      "799 106.59479522705078\n",
      "899 74.73704528808594\n",
      "999 53.30128860473633\n",
      "1099 38.86540985107422\n",
      "1199 29.134639739990234\n",
      "1299 22.569190979003906\n",
      "1399 18.13507080078125\n",
      "1499 15.137372016906738\n",
      "1599 13.10876750946045\n",
      "1699 11.734504699707031\n",
      "1799 10.802518844604492\n",
      "1899 10.169794082641602\n",
      "1999 9.739767074584961\n",
      "Result: y = 0.021941201761364937 + 0.8351587057113647 x + -0.00378522090613842 x^2 + -0.09026053547859192 x^3\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "# Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c00f563-5bca-4351-9598-40f4652c8066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94720a64-5915-4d8a-b917-b82660390f34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
